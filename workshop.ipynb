{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a RAG System Locally with Ollama, LlamaIndex, and Chroma DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 0 - Install Workshop Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the workshop, ensure all necessary dependencies are installed in your Python environment. Use the following steps to set up your environment.\n",
    "\n",
    "### Step 1: Create a Virtual Environment\n",
    "\n",
    "Create and activate a virtual environment to isolate the workshop dependencies. For this workshop, we use **Python 3.11**. Choose between **venv** or **conda** (using Mamba for efficiency).\n",
    "\n",
    "##### Using `venv`\n",
    "\n",
    "On Linux/Mac:\n",
    "  ```bash\n",
    "  python3.11 -m venv local-rag\n",
    "  source local-rag/bin/activate\n",
    "  ```\n",
    "On Windows:\n",
    "  ```bash\n",
    "  python3.11 -m venv local-rag\n",
    "  local-rag\\Scripts\\activate\n",
    "  ```\n",
    "\n",
    "##### Using `conda`\n",
    "\n",
    "   ```bash\n",
    "   conda create -n local-rag python=3.11\n",
    "   conda activate local-rag\n",
    "   ```\n",
    "\n",
    "### Step 2: Install Required Packages\n",
    "\n",
    "Install all the required dependencies:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Step 3: Verify Installation\n",
    "\n",
    "Check that the key packages are installed correctly by importing them in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import llama_index\n",
    "import ollama\n",
    "\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Setting up Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Ollama\n",
    "\n",
    "First, download and install Ollama from the official website: [https://ollama.com/download/](https://ollama.com/download/).\n",
    "\n",
    "### Pull Required Models\n",
    "\n",
    "Open a terminal and run the following commands to download the necessary models:\n",
    "\n",
    "1. Pull the `llama3` model:\n",
    "   ```bash\n",
    "   ollama pull llama3\n",
    "   ```\n",
    "\n",
    "2. Pull the Nomic embedding model if required:\n",
    "   ```bash\n",
    "   ollama pull nomic\n",
    "   ```\n",
    "\n",
    "### Run the Model\n",
    "\n",
    "Once the models are installed, you can run the `llama3` model and test it by writing some prompts. Use the following command:\n",
    "\n",
    "```bash\n",
    "ollama run llama3\n",
    "```\n",
    "\n",
    "Type a prompt and observe the output to ensure everything is working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with Ollama in Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPFL stands for École Polytechnique Fédérale de Lausanne, which is a Swiss federal institute of technology located in Lausanne, Switzerland. It is one of the two Swiss Federal Institutes of Technology (the other being ETH Zurich), and it is considered one of the best technical universities in the world.\n",
      "\n",
      "EPFL was founded in 1853 as the École d'ingénieurs de l'état, and it has since grown to become a leading institution in Switzerland for education and research in science, technology, engineering, and mathematics (STEM). The university has a strong reputation for its programs in fields such as computer science, electrical engineering, mechanical engineering, physics, chemistry, biology, and more.\n",
      "\n",
      "EPFL is known for its innovative teaching methods, which emphasize hands-on learning and collaboration between students and professors. The university also has a strong research focus, with many faculty members being world-renowned experts in their fields. EPFL has partnerships with other leading institutions around the world, including universities, research centers, and industries.\n",
      "\n",
      "EPFL is highly selective and competitive, attracting top talent from around the globe. Its bachelor's and master's programs are taught in French, while its Ph.D. programs are conducted in English. The university also offers executive education programs for professionals and has a strong focus on entrepreneurship and innovation."
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.generate(model=\"llama3\", prompt=\"What is EPFL?\", stream=True)\n",
    "\n",
    "for r in response:\n",
    "    print(r[\"response\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Getting Started with LlamaIndex and ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LlamaIndex** ([official site](https://llamaindex.ai)) is a framework for connecting LLMs with data sources, enabling efficient retrieval and interaction with structured or unstructured data.\n",
    "\n",
    "**Chroma** ([official site](https://www.trychroma.com)) is a vector database designed for managing embeddings and serving as a retrieval layer for LLM applications.\n",
    "\n",
    "In this exercise, we’ll explore how to set up and use LlamaIndex to index and retrieve data in a **Chroma** database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Let's download a PDF\n",
    "\n",
    "You can start by adding documents to the `./docs` folder. If you don't know what to use, we suggest downloading the PDF at the following link:\n",
    "\n",
    "https://observationofalostsoul.wordpress.com/wp-content/uploads/2011/05/the-gospel-of-the-flying-spaghetti-monster.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set Up Chroma as the Storage Backend\n",
    "\n",
    "Initialize the Chroma database and configure it for use with LlamaIndex. Here, we create an **Ephemeral Client** and collection, which stores data temporarily in memory without persisting it. This is ideal for testing and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"mydocs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a **Persistent Client** that will preserve your database across sessions with:\n",
    "\n",
    "```python\n",
    "client = chromadb.PersistentClient(path=\"/path/to/save/to\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set Up LlamaIndex connectors\n",
    "\n",
    "Configure LlamaIndex to connect with Chroma as the vector store and set up a storage context. A **storage context** is an abstraction that manages how data is stored and retrieved, enabling seamless integration with different storage backends like Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load and explore documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use LlamaIndex's `SimpleDirectoryReader` to **ingest documents from a directory**. This utility reads files from a specified directory and prepares them for indexing by splitting the content into manageable chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./docs\", recursive=True).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the content of the documents further with a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from llama_index.core.schema import MetadataMode, TextNode\n",
    "\n",
    "\n",
    "def data_to_df(nodes: List[TextNode]):\n",
    "    \"\"\"Convert a list of TextNode objects to a pandas DataFrame.\"\"\"\n",
    "    return pd.DataFrame([node.dict() for node in nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_</th>\n",
       "      <th>embedding</th>\n",
       "      <th>metadata</th>\n",
       "      <th>excluded_embed_metadata_keys</th>\n",
       "      <th>excluded_llm_metadata_keys</th>\n",
       "      <th>relationships</th>\n",
       "      <th>text</th>\n",
       "      <th>mimetype</th>\n",
       "      <th>start_char_idx</th>\n",
       "      <th>end_char_idx</th>\n",
       "      <th>text_template</th>\n",
       "      <th>metadata_template</th>\n",
       "      <th>metadata_seperator</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5cbb133c-4d4d-4d5b-88bd-5e7649397c22</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '1', 'file_name': 'the-gospel-o...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>text/plain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>881a8f06-e8f3-492a-86b8-7e914ab4125e</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '2', 'file_name': 'the-gospel-o...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{}</td>\n",
       "      <td>BOBBY HENDERSON</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f548c13a-455d-4950-b1b0-e69e688d8bd0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '3', 'file_name': 'the-gospel-o...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{}</td>\n",
       "      <td>A Villard Books Trade Paperback Original \\nCop...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>794c260b-04c0-4900-b2ce-770330eb08a1</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '4', 'file_name': 'the-gospel-o...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{}</td>\n",
       "      <td>In the beginning was the Word, \\nand the Word ...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ba38dcb-b39f-4134-b7d7-0bd47baa4f15</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '5', 'file_name': 'the-gospel-o...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{}</td>\n",
       "      <td>Ackn owl ed gm en ts \\nDELIVERING A DIVINE MES...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Document</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id_ embedding  \\\n",
       "0  5cbb133c-4d4d-4d5b-88bd-5e7649397c22      None   \n",
       "1  881a8f06-e8f3-492a-86b8-7e914ab4125e      None   \n",
       "2  f548c13a-455d-4950-b1b0-e69e688d8bd0      None   \n",
       "3  794c260b-04c0-4900-b2ce-770330eb08a1      None   \n",
       "4  1ba38dcb-b39f-4134-b7d7-0bd47baa4f15      None   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'page_label': '1', 'file_name': 'the-gospel-o...   \n",
       "1  {'page_label': '2', 'file_name': 'the-gospel-o...   \n",
       "2  {'page_label': '3', 'file_name': 'the-gospel-o...   \n",
       "3  {'page_label': '4', 'file_name': 'the-gospel-o...   \n",
       "4  {'page_label': '5', 'file_name': 'the-gospel-o...   \n",
       "\n",
       "                        excluded_embed_metadata_keys  \\\n",
       "0  [file_name, file_type, file_size, creation_dat...   \n",
       "1  [file_name, file_type, file_size, creation_dat...   \n",
       "2  [file_name, file_type, file_size, creation_dat...   \n",
       "3  [file_name, file_type, file_size, creation_dat...   \n",
       "4  [file_name, file_type, file_size, creation_dat...   \n",
       "\n",
       "                          excluded_llm_metadata_keys relationships  \\\n",
       "0  [file_name, file_type, file_size, creation_dat...            {}   \n",
       "1  [file_name, file_type, file_size, creation_dat...            {}   \n",
       "2  [file_name, file_type, file_size, creation_dat...            {}   \n",
       "3  [file_name, file_type, file_size, creation_dat...            {}   \n",
       "4  [file_name, file_type, file_size, creation_dat...            {}   \n",
       "\n",
       "                                                text    mimetype  \\\n",
       "0                                                     text/plain   \n",
       "1                                   BOBBY HENDERSON   text/plain   \n",
       "2  A Villard Books Trade Paperback Original \\nCop...  text/plain   \n",
       "3  In the beginning was the Word, \\nand the Word ...  text/plain   \n",
       "4  Ackn owl ed gm en ts \\nDELIVERING A DIVINE MES...  text/plain   \n",
       "\n",
       "  start_char_idx end_char_idx                text_template metadata_template  \\\n",
       "0           None         None  {metadata_str}\\n\\n{content}    {key}: {value}   \n",
       "1           None         None  {metadata_str}\\n\\n{content}    {key}: {value}   \n",
       "2           None         None  {metadata_str}\\n\\n{content}    {key}: {value}   \n",
       "3           None         None  {metadata_str}\\n\\n{content}    {key}: {value}   \n",
       "4           None         None  {metadata_str}\\n\\n{content}    {key}: {value}   \n",
       "\n",
       "  metadata_seperator class_name  \n",
       "0                 \\n   Document  \n",
       "1                 \\n   Document  \n",
       "2                 \\n   Document  \n",
       "3                 \\n   Document  \n",
       "4                 \\n   Document  "
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df = data_to_df(documents)\n",
    "\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe several attributes, including `metadata`, `text`, `text_template`, and others. Let's focus on these three key categories:\n",
    "\n",
    "- **`metadata`**: This attribute contains additional information about the document, such as its source, creation date, or tags that can be used for filtering or retrieval purposes.\n",
    "- **`text`**: The main content of the document, representing the raw textual data that will be indexed and queried.\n",
    "- **`text_template`**: A structured format or schema for the document's text, often used to define how the content should be presented or processed during queries. \n",
    "\n",
    "These attributes play distinct roles in organizing and interacting with your data. Feel free to explore the different attributes at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Index and the documents\n",
    "\n",
    "To ingest documents into an index, we will need an embedder model to convert the document content into vector representations. These embeddings enable efficient similarity searches and retrievals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In LlamaIndex, we can create an index using the `VectorStoreIndex` class, which enables efficient storage and retrieval of document embeddings and integrates with various storage backends and embedding models. We use here the chroma collection we previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 178/178 [00:00<00:00, 3107.49it/s]\n",
      "Generating embeddings: 100%|██████████| 178/178 [00:10<00:00, 17.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Query the Index for Retrieval\n",
    "\n",
    "Once the documents are indexed, we can perform retrieval on them. This allows us to ask questions or search for relevant content based on the embeddings stored in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_</th>\n",
       "      <th>embedding</th>\n",
       "      <th>metadata</th>\n",
       "      <th>excluded_embed_metadata_keys</th>\n",
       "      <th>excluded_llm_metadata_keys</th>\n",
       "      <th>relationships</th>\n",
       "      <th>text</th>\n",
       "      <th>mimetype</th>\n",
       "      <th>start_char_idx</th>\n",
       "      <th>end_char_idx</th>\n",
       "      <th>text_template</th>\n",
       "      <th>metadata_template</th>\n",
       "      <th>metadata_seperator</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58aed9a8-f226-48cb-9e01-d245d2daf98d</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '66', 'file_name': 'the-gospel-...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{'NodeRelationship.SOURCE': {'node_id': '29abd...</td>\n",
       "      <td>Key Moments in FSM History • • 59 \\nOriginally...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>TextNode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125169e1-9b61-47d6-bfc7-88e444cde9d9</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '138', 'file_name': 'the-gospel...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{'NodeRelationship.SOURCE': {'node_id': 'cb791...</td>\n",
       "      <td>1 34« -The Gospel of the Flying Spaghetti Mons...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>TextNode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d77af2c6-ff05-4215-b63c-a0a9067caeb2</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '65', 'file_name': 'the-gospel-...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{'NodeRelationship.SOURCE': {'node_id': '2e43c...</td>\n",
       "      <td>58 • 'Che Gospel of the Flying Spaghetti Monst...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>TextNode</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id_ embedding  \\\n",
       "0  58aed9a8-f226-48cb-9e01-d245d2daf98d      None   \n",
       "1  125169e1-9b61-47d6-bfc7-88e444cde9d9      None   \n",
       "2  d77af2c6-ff05-4215-b63c-a0a9067caeb2      None   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'page_label': '66', 'file_name': 'the-gospel-...   \n",
       "1  {'page_label': '138', 'file_name': 'the-gospel...   \n",
       "2  {'page_label': '65', 'file_name': 'the-gospel-...   \n",
       "\n",
       "                        excluded_embed_metadata_keys  \\\n",
       "0  [file_name, file_type, file_size, creation_dat...   \n",
       "1  [file_name, file_type, file_size, creation_dat...   \n",
       "2  [file_name, file_type, file_size, creation_dat...   \n",
       "\n",
       "                          excluded_llm_metadata_keys  \\\n",
       "0  [file_name, file_type, file_size, creation_dat...   \n",
       "1  [file_name, file_type, file_size, creation_dat...   \n",
       "2  [file_name, file_type, file_size, creation_dat...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'NodeRelationship.SOURCE': {'node_id': '29abd...   \n",
       "1  {'NodeRelationship.SOURCE': {'node_id': 'cb791...   \n",
       "2  {'NodeRelationship.SOURCE': {'node_id': '2e43c...   \n",
       "\n",
       "                                                text    mimetype  \\\n",
       "0  Key Moments in FSM History • • 59 \\nOriginally...  text/plain   \n",
       "1  1 34« -The Gospel of the Flying Spaghetti Mons...  text/plain   \n",
       "2  58 • 'Che Gospel of the Flying Spaghetti Monst...  text/plain   \n",
       "\n",
       "   start_char_idx  end_char_idx                text_template  \\\n",
       "0               0           363  {metadata_str}\\n\\n{content}   \n",
       "1               0          2198  {metadata_str}\\n\\n{content}   \n",
       "2               0           580  {metadata_str}\\n\\n{content}   \n",
       "\n",
       "  metadata_template metadata_seperator class_name  \n",
       "0    {key}: {value}                 \\n   TextNode  \n",
       "1    {key}: {value}                 \\n   TextNode  \n",
       "2    {key}: {value}                 \\n   TextNode  "
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = index.as_retriever(\n",
    "    similarity_top_k=3,\n",
    ")\n",
    "\n",
    "nodes_with_score = retriever.retrieve(\"What is the Flying Spaghetti Monster?\")\n",
    "nodes = [n.node for n in nodes_with_score]\n",
    "data_to_df(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You've retrieved your first data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Your First RAG!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a Retrieval-Augmented Generation (RAG) system, you need a Large Language Model (LLM) to generate answers to your queries by combining retrieved knowledge with the model's reasoning capabilities. At this point, Ollama comes to help as the LLM powering your RAG system. We set it up for LlamaIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is ready for querying your data. You can define a query engine and start asking it questions. Congrats, You have a working RAG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similarity_top_k=3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What is the Flying Spaghetti Monster?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A creator deity who has touched every continent and culture, leaving His mark with His Noodly Appendage."
     ]
    }
   ],
   "source": [
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, a basic retriever is used. You can see that the same nodes are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_</th>\n",
       "      <th>embedding</th>\n",
       "      <th>metadata</th>\n",
       "      <th>excluded_embed_metadata_keys</th>\n",
       "      <th>excluded_llm_metadata_keys</th>\n",
       "      <th>relationships</th>\n",
       "      <th>text</th>\n",
       "      <th>mimetype</th>\n",
       "      <th>start_char_idx</th>\n",
       "      <th>end_char_idx</th>\n",
       "      <th>text_template</th>\n",
       "      <th>metadata_template</th>\n",
       "      <th>metadata_seperator</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58aed9a8-f226-48cb-9e01-d245d2daf98d</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '66', 'file_name': 'the-gospel-...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{'NodeRelationship.SOURCE': {'node_id': '29abd...</td>\n",
       "      <td>Key Moments in FSM History • • 59 \\nOriginally...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>TextNode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125169e1-9b61-47d6-bfc7-88e444cde9d9</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '138', 'file_name': 'the-gospel...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{'NodeRelationship.SOURCE': {'node_id': 'cb791...</td>\n",
       "      <td>1 34« -The Gospel of the Flying Spaghetti Mons...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>TextNode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d77af2c6-ff05-4215-b63c-a0a9067caeb2</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '65', 'file_name': 'the-gospel-...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{'NodeRelationship.SOURCE': {'node_id': '2e43c...</td>\n",
       "      <td>58 • 'Che Gospel of the Flying Spaghetti Monst...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>TextNode</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id_ embedding  \\\n",
       "0  58aed9a8-f226-48cb-9e01-d245d2daf98d      None   \n",
       "1  125169e1-9b61-47d6-bfc7-88e444cde9d9      None   \n",
       "2  d77af2c6-ff05-4215-b63c-a0a9067caeb2      None   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'page_label': '66', 'file_name': 'the-gospel-...   \n",
       "1  {'page_label': '138', 'file_name': 'the-gospel...   \n",
       "2  {'page_label': '65', 'file_name': 'the-gospel-...   \n",
       "\n",
       "                        excluded_embed_metadata_keys  \\\n",
       "0  [file_name, file_type, file_size, creation_dat...   \n",
       "1  [file_name, file_type, file_size, creation_dat...   \n",
       "2  [file_name, file_type, file_size, creation_dat...   \n",
       "\n",
       "                          excluded_llm_metadata_keys  \\\n",
       "0  [file_name, file_type, file_size, creation_dat...   \n",
       "1  [file_name, file_type, file_size, creation_dat...   \n",
       "2  [file_name, file_type, file_size, creation_dat...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'NodeRelationship.SOURCE': {'node_id': '29abd...   \n",
       "1  {'NodeRelationship.SOURCE': {'node_id': 'cb791...   \n",
       "2  {'NodeRelationship.SOURCE': {'node_id': '2e43c...   \n",
       "\n",
       "                                                text    mimetype  \\\n",
       "0  Key Moments in FSM History • • 59 \\nOriginally...  text/plain   \n",
       "1  1 34« -The Gospel of the Flying Spaghetti Mons...  text/plain   \n",
       "2  58 • 'Che Gospel of the Flying Spaghetti Monst...  text/plain   \n",
       "\n",
       "   start_char_idx  end_char_idx                text_template  \\\n",
       "0               0           363  {metadata_str}\\n\\n{content}   \n",
       "1               0          2198  {metadata_str}\\n\\n{content}   \n",
       "2               0           580  {metadata_str}\\n\\n{content}   \n",
       "\n",
       "  metadata_template metadata_seperator class_name  \n",
       "0    {key}: {value}                 \\n   TextNode  \n",
       "1    {key}: {value}                 \\n   TextNode  \n",
       "2    {key}: {value}                 \\n   TextNode  "
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_with_score = response.source_nodes\n",
    "nodes = [n.node for n in nodes_with_score]\n",
    "data_to_df(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "# custome prompt template\n",
    "template = (\n",
    "    \"Imagine you are an advanced AI expert in cyber security laws, with access to all current and relevant legal documents, \"\n",
    "    \"case studies, and expert analyses. Your goal is to provide insightful, accurate, and concise answers to questions in this domain.\\n\\n\"\n",
    "    \"Here is some context related to the query:\\n\"\n",
    "    \"-----------------------------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"-----------------------------------------\\n\"\n",
    "    \"Considering the above information, please respond to the following inquiry with detailed references to applicable laws, \"\n",
    "    \"precedents, or principles where appropriate:\\n\\n\"\n",
    "    \"Question: {query_str}\\n\\n\"\n",
    "    \"Answer succinctly, starting with the phrase 'According to cyber security law,' and ensure your response is understandable to someone without a legal background.\"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similartiy_top_k=3,\n",
    "    streaming=True,\n",
    "    text_qa_template=qa_template,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What is Red Teaming?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.extractors import TitleExtractor\n",
    "from llama_index.core.ingestion import IngestionCache, IngestionPipeline\n",
    "from llama_index.core.node_parser import SentenceSplitter, SentenceWindowNodeParser\n",
    "\n",
    "sentence_splitter = SentenceSplitter()\n",
    "\n",
    "sentence_window_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=5,\n",
    "    include_prev_next_rel=True,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "\n",
    "# create the pipeline with transformations\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        sentence_window_parser,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pipeline.run(documents=documents[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_nodes(nodes).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = nodes[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.excluded_embed_metadata_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The LLM sees this: \\n\",\n",
    "    node.get_content(metadata_mode=MetadataMode.LLM),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.metadata[\"window\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The Embedding model sees this: \\n\",\n",
    "    node.get_content(metadata_mode=MetadataMode.EMBED),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "node_postprocessors = (\n",
    "    [MetadataReplacementPostProcessor(target_metadata_key=\"window\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now embed our documents and store them in a ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index.vector_store.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_collection.get()[\"metadatas\"][0][\"window\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.vector_store.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Your First RAG!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first practice the retrieval of a document based on a the similarity with a query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check which sources were identified to be the most relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.get_formatted_sources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.source_nodes[0].node.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similartiy_top_k=3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What is Red Teaming?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similartiy_top_k=3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What is Red Teaming?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's practice the reprompting of our LLM with a custom template, in which the relevant context will be fed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "# custome prompt template\n",
    "template = (\n",
    "    \"Imagine you are an advanced AI expert in cyber security laws, with access to all current and relevant legal documents, \"\n",
    "    \"case studies, and expert analyses. Your goal is to provide insightful, accurate, and concise answers to questions in this domain.\\n\\n\"\n",
    "    \"Here is some context related to the query:\\n\"\n",
    "    \"-----------------------------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"-----------------------------------------\\n\"\n",
    "    \"Considering the above information, please respond to the following inquiry with detailed references to applicable laws, \"\n",
    "    \"precedents, or principles where appropriate:\\n\\n\"\n",
    "    \"Question: {query_str}\\n\\n\"\n",
    "    \"Answer succinctly, starting with the phrase 'According to cyber security law,' and ensure your response is understandable to someone without a legal background.\"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similartiy_top_k=3,\n",
    "    streaming=True,\n",
    "    text_qa_template=qa_template,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What is Red Teaming?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.print_response_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lauzhack-workshop-2024-7gra-v0p-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
